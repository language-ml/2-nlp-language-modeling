{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d7af06",
   "metadata": {},
   "source": [
    "<img src='images/besm.png' width='150px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d8d23b",
   "metadata": {},
   "source": [
    "<center> درس پردازش زبان‌های طبیعی </center>\n",
    "<center> آزمایشگاه پردازش هوشمند متن و زبان و علوم انسانی محاسباتی </center>\n",
    "<br>\n",
    "<center> http://language.ml </center>\n",
    "<center> contact: asgari [AT] berkeley [dot] edu </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2faf6d",
   "metadata": {},
   "source": [
    "</h1> <h1 style='direction:rtl'>مدل زبانی \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20495294",
   "metadata": {},
   "source": [
    "<h2 style='direction:rtl;'> اشعار حافظ و سعدی  </h2> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5958fd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329707/329707 [00:00<00:00, 640175.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import tqdm\n",
    "    \n",
    "# Hafez and Saadi collection -- Hafez [0:8384] Saadi[9384::]\n",
    "HAFEZ_end=8384\n",
    "SAADI_start=9384\n",
    "mesra_collection = [x.strip().split() for x in tqdm.tqdm(codecs.open('farsi/mesra.txt','rU','utf-8').readlines())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f459070",
   "metadata": {},
   "source": [
    "<h4 style='direction:rtl;'> مثال بررسی اولیه داده غزلیات فارسی. برای مطالعه بیشتر به مقاله زیر مراجعه کنید  </h4> \n",
    "\n",
    "<br/>\n",
    "\n",
    "Asgari, Ehsaneddin, and Jean-Cédric Chappelier. <b>Linguistic resources and topic models for the analysis of persian poems.</b> <i>Proceedings of NAACL-HLT Workshop on Computational Linguistics for Literature. 2013 </i>.\n",
    "\n",
    "https://aclanthology.org/W13-1404.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed5ba9",
   "metadata": {},
   "source": [
    "<h2 style='direction:rtl;'> § نرمالایز کردن  </h2> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd3f0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329707/329707 [00:38<00:00, 8581.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "\n",
    "normalizer = Normalizer()\n",
    "\n",
    "mesra_normalized = [[normalizer.normalize(y) for y in x] for x in tqdm.tqdm(mesra_collection)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f142d4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "چو خاتونان مصر از عشق یوسف\n",
      "زیر هر توی آن سخن توییست\n",
      "حلقه دیوانگی زد، عقل و راه در گرفت\n",
      "ندامت برد از آیینه‌ام زنگ هوس بید‌ل\n",
      "پیوسته بوی باغ و گلستانم آرزوست\n",
      "پیدا کند ز پوست مگر پرده‌دار مغز\n",
      "زیرا که غمش کمی ندارد\n",
      "گه در نظارهٔ خویش، گه در خیال مردم\n",
      "زر بازدهی و بنهی سر به حجر بر\n",
      "خدای گفت قم اللیل و از گزاف نگفت\n",
      "کشتی مساز نوح که طوفان آتش است\n",
      "هر که او دیدهٔ مردم کش مستت دیدست\n",
      "چون به یک دم صد جهان واپس کنم\n",
      "هر بی خبر چگونه خبر زان دهان دهد\n",
      "این کتاب نیک می دانیم ما\n",
      "سخن عشق، که عقلم به معما می‌خواند\n",
      "که چون خورشیدم از روزن نظر کرد\n",
      "هم از دل خود گردد در هر نفسی خوشتر\n",
      "در هم نگرستیم و گرستیم و گذشتیم\n",
      "چون کنم چون مرغ دل در دام آن زنجیر موست\n",
      "شتاب کن که جهان با شتاب می گذرد\n",
      "زود باشد کز خجالت رو به دیوار آورد\n",
      "موج هرجا، در جمعیت‌گوهر زده است\n",
      "که از جفای تو دستی بر آسمان دارم\n",
      "چون نیست یقین که محض جانی\n",
      "بازآمدی کف می‌زنی تا خانه‌ها ویران کنی\n",
      "آخر این جیب هوس پردهٔ ناموس نبود\n",
      "نیست بی‌خشکی لب گر همه دریا باشد\n",
      "کرده از گوشه کنارم هدف ناوک ناز\n",
      "نوای زیر و بم از جان مرغ زار برآید\n"
     ]
    }
   ],
   "source": [
    "for x in random.sample(mesra_normalized, 30):\n",
    "    print(' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61c9cb",
   "metadata": {},
   "source": [
    "<h2 style='direction:rtl;'> § جمله‌بندی  </h2> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f47d62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329707/329707 [00:01<00:00, 246679.93it/s]\n"
     ]
    }
   ],
   "source": [
    "mesra_sentences = [sent_tokenize(' '.join(x)) for x in tqdm.tqdm(mesra_normalized)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44124d",
   "metadata": {},
   "source": [
    "<h2 style='direction:rtl;'> § توکنایزیشن  </h2> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "99815c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329707/329707 [00:04<00:00, 79082.94it/s] \n"
     ]
    }
   ],
   "source": [
    "mesra_tokens = [[word_tokenize(sent) for sent in sents][0] for sents in tqdm.tqdm(mesra_sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ceae4d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['که', 'در', 'ظلمت', 'ز', 'آمدشد', 'پری', 'را', 'پای', 'می', 'سایم'],\n",
       " ['گر',\n",
       "  'همه',\n",
       "  'اشکی',\n",
       "  'به',\n",
       "  'دست',\n",
       "  'آید',\n",
       "  'تو',\n",
       "  'را',\n",
       "  '،',\n",
       "  'آن',\n",
       "  'هم',\n",
       "  'فرست'],\n",
       " ['عدل', 'مثال', 'مشعله', 'ظلم', 'چو', 'کور', 'یا', 'کری'],\n",
       " ['بنشین', 'یکدم', 'و', 'برآتش', 'تیزم', 'منشان'],\n",
       " ['در', 'کتاب', 'آفرینش', 'جمله', 'خط', 'توأمیم'],\n",
       " ['تختگاه', 'عشق', 'ما', 'داریم', 'و', 'از', 'دار', 'ایمنیم'],\n",
       " ['خار', 'سودای', 'تو', 'در', 'دل', 'به', 'هوای', 'گل', 'وصل'],\n",
       " ['به', 'خویش', 'چشم\\u200cگشودن', 'وداع', 'فرصت', 'بود'],\n",
       " ['با', 'برهمن', 'مگو', 'سخن', 'شرع', 'بعد', 'ازین'],\n",
       " ['بجز', 'این', 'معنی', 'باریک', 'نیامد', 'بیرون'],\n",
       " ['زنده', 'باشیم', 'و', 'همه', 'روضه', 'بخوانیم', 'که', 'چه'],\n",
       " ['درگیر', 'شمع', 'را', 'وز', 'سر', 'تا', 'به', 'پا', 'بپرس'],\n",
       " ['چشم', 'تابرهم', 'زنم', 'اشکی', 'به\\u200cخون', 'غلتیده', 'است'],\n",
       " ['که', 'تا', 'دست', 'خدا', 'بر', 'رویت', 'ازاغبار', 'در', 'بندد'],\n",
       " ['کسی', 'که', 'گشته', 'به', 'تقلید', 'آدمی', 'سیر', 'ت'],\n",
       " ['وگر', 'پنهان', 'نه\\u200cای', '،', 'پیدا', 'کجایی', '؟'],\n",
       " ['این', 'خواجه', 'بوق', 'می\\u200cزند', 'اقبال', 'چنگ', 'و', 'دف'],\n",
       " ['کسی', 'چه', 'شکرکند', 'دولت', 'تمنا', 'را'],\n",
       " ['تا', 'من', 'باشی', 'تو', 'او', 'نبینی'],\n",
       " ['منزل', 'مقصود', 'گام', 'اول', 'افتادگی\\u200cست'],\n",
       " ['مفارقت', 'نکنم', 'دیگر', 'از', 'حریم', 'حرم'],\n",
       " ['بر', 'آن', 'کو', 'میدهد', 'جان', 'میبرم', 'رشگ'],\n",
       " ['صبر', 'کن', 'ای', 'دل', 'که', 'صبر', 'سیرت', 'اهل', 'صفاست'],\n",
       " ['موج', 'دریا', 'را', 'تپیدن', 'رقص', 'عیش', 'زندگی\\u200cست'],\n",
       " ['درین', 'ره', 'هر', 'که', 'نعلینی', 'بینداخت'],\n",
       " ['بیشتر', 'آ', 'گوهرا', 'تا', 'همه', 'دریا', 'رویم'],\n",
       " ['سخته', 'کمانیست', '،', 'پس', 'این', 'کمین'],\n",
       " ['وحدت', 'به', 'هیچ', 'جلوه', 'مقابل', 'نمی\\u200cشود'],\n",
       " ['از',\n",
       "  'هوس',\n",
       "  'تا',\n",
       "  'کی\\u200c',\n",
       "  'کسی',\n",
       "  'پالان\\u200c',\n",
       "  'گاو',\n",
       "  'و',\n",
       "  'خر',\n",
       "  'شود'],\n",
       " ['که', 'عقل', 'بر', 'سر', 'بازار', 'عشق', 'حیران', 'است']]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(mesra_tokens, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f1e9d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<h2 style='direction:rtl;'> § مدل زبانی</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d86c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import nltk\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "def create_language_model(unigrams, bigrams, unigrams_counts, bigrams_counts):\n",
    "    '''The language_model is a nested dictionary where each key is a word w from the\n",
    "    poetry collection, and each value is another dictionary with all of the words\n",
    "    that could possible follow w (and their associated probabilities based on MLE).\n",
    "    '''\n",
    "    language_model = defaultdict(dict)  #initialize a dictionary where each key has another dictionary as its value\n",
    "\n",
    "    for bigram in bigrams:\n",
    "        w_i_minus1 = bigram[0]   #first word\n",
    "        w_i = bigram[1]          #second word\n",
    "        language_model[w_i_minus1][w_i] = bigrams_counts[bigram]/unigrams_counts[w_i_minus1]   #this is MLE calculation\n",
    "    \n",
    "    return language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924193c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unigram counts (to be used as denominators)\n",
    "unigrams =list(itertools.chain(*list(itertools.chain(*mesra_tokens))))\n",
    "unigrams_counts = Counter(unigrams)\n",
    "\n",
    "# find bigram counts (to be used as numerators)\n",
    "bigrams = list(nltk.bigrams(unigrams))\n",
    "bigrams_counts = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100da5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['ز','ار']+[normalizer.normalize(x.strip()) for x in codecs.open('farsi/stopwords.txt','r','utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17daae9",
   "metadata": {},
   "source": [
    "# Unigram language model of Hafez/Saadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "966e9a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c4493280>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEDCAYAAAAvNJM9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbsUlEQVR4nO3de5RdZZ3m8e9TVUkl5EYglRgIbRJFMa0SoCaN0k1juBgiA06r02Ha6bTai/HWo86atsNo69JePa2O00udscUsWmQa5SItEkMgRCACDSRUFuRGEnIhmFCQKi65kUulqn7zx3krnBRv3U9VpU49n7X2Onu/e797v++pWuc5+3L2VkRgZmbWXsVgN8DMzE5ODggzM8tyQJiZWZYDwszMshwQZmaW5YAwM7OskzYgJP1EUoOkDSVa332S9kpa2q78Z5K2SNqQtjmilG1UwQ8kbZO0TtL5qXyUpNWS1kraKOkbRXX+l6TNafm7JJ2aykdKuknS+lTvkqI6f5qW3yjpO0Xl1ZJuT9tfJWl60byFkramYWFR+Yy07NZUd2RnfUnz5qX3cZukRd19DzsjqUXS02lYUop1mlkPRMRJOQAXA+cDG0q0vkuBfw8sbVc+H1AabgU+k6n7U+CS3rQxrf/etP4LgVWpXMDYND4CWAVcmKavAKrS+LeBb6fxzwE3pfHJwBoKIX868DugJs27Gbg0jX8WuCGNLwBuT+OnATvS68Q0PjHNuwNYkMZvaHtPOulLJbAdmAmMBNYCs0rwNzs42P+HHjwM5+Gk3YOIiIeBV4vLJL0t7QmskfSIpHN6sL4HgAOZ8mWRAKuBaX1pY8Y1wP9Lm3gCOFXS1DR9MC0zIg2R1nt/RDSneU8UtWkW8EBapgHYC9RS+GB+NiIa03K/AT5StP2b0/idwKWSBHwQWBERr0bEa8AKYF6aNzctS6r74c76AswBtkXEjohoAm5Ly/bpb2Zmg+ukDYgOLAb+KiIuAP478E+lWnE6tPSfgftKtc7kTGBX0fTuVIakSklPAw0UPqxXZep/ksK3dih8M79GUpWkGcAFwFnANuAcSdMlVVH4QD+r/fZT6OyjsMfRUbtOB/YWBdTx9nZSp8M+0re/2ShJdZKekPThHtQzsxKoGuwGdJekscD7gV8UvuQCUJ3m/QnwzUy1FyLig93cxD8BD0fEI2mdH6RweAfg94A/lHQQOBoRf9CTpmfK2vYUWoDZ6RzDXZLeHRHHz2dI+grQDPwsFf0EeBdQBzwPPAY0R8Rrkj4D3A60pvKZXWy/p+U9XlcJ/ma/FxH1kmYCD0paHxHbM3XMrB8MmYCgsLezNyJmt58REb8EftnbFUv6OlAD/JeidS4Hlqf5PwV+GhEre7H63bzxbR4Kh4vqixeIiL2SVgLzgA1pmwuBqyicS2gLlGbgS0XtfgzYmub9Gvh1Kr8OaGm3/d1p72IChcNiu4FL2rVrJfAyhUNHVWl7xe3tqC8jOyjv098sIurT6470/pxH4VyHmQ2AIXOIKSL2A89J+hgcv6Lm3L6uV9JfUjgef21EtPZ1fRlLgD9P7b0Q2BcRL0qqKbo6aTRwGbA5Tc8D/ga4OiIOFbX1FElj0vjlFPYenknTk9PrRAonpm8s2n7bFUofBR5MgbMcuELSxFTnCmB5mvdQWpZU9+7O+gI8CZydrn4aSeFk+JK+/M1Su9r2NiYBFwHPdKeumZXIYJ8l72igcEXRi8AxCt9cPwXMoHCOYC2FD4uv9WB9jwCNwOG0vg+m8mYK30qfTsOb1knHVzG9qY2p/NPAp9O4gB+mbawHalP5e4GngHUU9hq+VrTebRSO6be1qe0qpOnAFmAThRPRb23XlmfSsKCofBTwi7TO1cDMonmfTOXbgE8Ulc9My25Ldas760uaNx94Ns37SlF5r/5mFA5NrU/11re9tx48eBi4QRG+3beZmb3ZkDnEZGZmA+ukPEk9adKkmD59+mA3w8xsyFizZs3LEVFTynWelAExffp06urqBrsZZmZDhqTnS71OH2IyM7MsB4SZmWU5IMzMLMsBYWZmWQ4IMzPLckCYmVmWA8LMzLK6HRDp2QVPKT2yU9LHVHi8Zauk2k7qlfxRlB357bON7Hr1UNcLmplZl3qyB/EFCjeJa7MB+BPg4Y4qSKqkcHO3Kyk8De1aSbN60c5uWfiT1Vz6v3/bX6s3MxtWuhUQkqYBH+KNW0gTEZsiYksXVTt8FGV/aWrpjzt2m5kNP93dg/ge8GUKTyvric4eRWlmZiexLgNC0lVAQ0Ss6cX6O3t8ZfvtXJeeP1zX2NjYi02ZmVkpdWcP4iLgakk7KRwimivplm6uv8vHbbaJiMURURsRtTU1Jb0hoZmZ9UKXARER10fEtIiYTuFRkg9GxMe7uf7soyh73VozMxswvf4dhKT/IGk38D7gHknLU/kZkpYBROGh95+n8PzjTcAdEbGx7802M7P+1qPnQUTESmBlGr8LuCuzTD2F5xO3TS8DlvWlkWZmNvD8S2ozM8tyQJiZWZYDwszMshwQZmaW5YAwM7MsB4SZmWU5IMzMLMsBYWZmWQ4IMzPLckCYmVmWA8LMzLIcEGZmluWAMDOzLAeEmZllOSDMzCzLAWFmZlkOCDMzy3JAmJlZlgPCzMyyHBBmZpblgDAzsywHhJmZZTkgzMwsywFhZmZZDggzM8tyQJiZWZYDwszMsrodEJIqJT0laWmaPk3SCklb0+vEDurtlLRe0tOS6krVcDMz61892YP4ArCpaHoR8EBEnA08kKY78oGImB0Rtb1oo5mZDYJuBYSkacCHgBuLiq8Bbk7jNwMfLmnLzMxsUHV3D+J7wJeB1qKyKRHxIkB6ndxB3QDul7RG0nUdbUDSdZLqJNU1NjZ2s1lmZtZfugwISVcBDRGxppfbuCgizgeuBD4n6eLcQhGxOCJqI6K2pqaml5syM7NS6c4exEXA1ZJ2ArcBcyXdAuyRNBUgvTbkKkdEfXptAO4C5pSg3WZm1s+6DIiIuD4ipkXEdGAB8GBEfBxYAixMiy0E7m5fV9IYSePaxoErgA0laruZmfWjvvwO4lvA5ZK2ApenaSSdIWlZWmYK8KiktcBq4J6IuK8vDTYzs4FR1ZOFI2IlsDKNvwJcmlmmHpifxncA5/a1kWZmNvD8S2ozM8tyQJiZWZYDwszMshwQZmaW5YAwM7MsB4SZmWU5IMzMLMsBYWZmWQ4IMzPLckCYmVmWA8LMzLIcEGZmluWAMDOzLAeEmZllOSDMzCzLAWFmZlkOCDMzy3JAmJlZlgPCzMyyHBBmZpblgDAzsywHhJmZZTkgzMwsywFhZmZZDggzM8tyQJiZWVa3A0JSpaSnJC1N06dJWiFpa3qd2EG9eZK2SNomaVGpGm5mZv2rJ3sQXwA2FU0vAh6IiLOBB9L0CSRVAj8ErgRmAddKmtX75pqZ2UDpVkBImgZ8CLixqPga4OY0fjPw4UzVOcC2iNgREU3AbamemZmd5Lq7B/E94MtAa1HZlIh4ESC9Ts7UOxPYVTS9O5W9iaTrJNVJqmtsbOxms8zMrL90GRCSrgIaImJNL9avTFnkFoyIxRFRGxG1NTU1vdjUG1pbs5swM7Me6M4exEXA1ZJ2UjhENFfSLcAeSVMB0mtDpu5u4Kyi6WlAfZ9a3A0/+u32/t6EmVnZ6zIgIuL6iJgWEdOBBcCDEfFxYAmwMC22ELg7U/1J4GxJMySNTPWXlKTlnVj13Kv9vQkzs7LXl99BfAu4XNJW4PI0jaQzJC0DiIhm4PPAcgpXQN0RERv71mQzMxsIVT1ZOCJWAivT+CvApZll6oH5RdPLgGV9aaSZmQ08/5LazMyyHBBmZpblgDAzsywHhJmZZTkgzMwsywFhZmZZDggzM8tyQJiZWVZZBkTuDoFmZtYzZRkQZmbWdw4IMzPLckCYmVmWA8LMzLIcEGZmluWAMDOzLAeEmZllOSDMzCzLAWFmZlkOCDMzyyrLgJDvtWFm1mdlGRBmZtZ3ZRkQ3oEwM+u7sgwIMzPrOweEmZllOSDMzCzLAWFmZllVXS0gaRTwMFCdlr8zIr4u6VzgBmAssBP4s4jYn6m/EzgAtADNEVFbstabmVm/6c4exFFgbkScC8wG5km6ELgRWBQR7wHuAv66k3V8ICJmOxzMzIaOLgMiCg6myRFpCOCdFPYsAFYAH+mXFpqZ2aDo1jkISZWSngYagBURsQrYAFydFvkYcFYH1QO4X9IaSdd1so3rJNVJqmtsbOx2B8zMrH90KyAioiUiZgPTgDmS3g18EvicpDXAOKCpg+oXRcT5wJVp+Ys72MbiiKiNiNqampqe9uME8r02zMz6rEdXMUXEXmAlMC8iNkfEFRFxAXArsL2DOvXptYHCuYo5fWmwmZkNjC4DQlKNpFPT+GjgMmCzpMmprAL4KoUrmtrXHSNpXNs4cAWFQ1NmZnaS684exFTgIUnrgCcpnINYClwr6VlgM1AP3AQg6QxJy1LdKcCjktYCq4F7IuK+UnfCzMxKr8vfQUTEOuC8TPn3ge9nyuuB+Wl8B3Bu35tpZmYDzb+kNjOzLAeEmZllOSDMzCzLAWFmZlkOCDMzy3JAmJlZVlkGhG+0YWbWd2UZEGZm1ncOCDMzy3JAmJlZlgPCzMyyyjIg/DgIM7O+K8uAMDOzvnNAmJlZlgPCzMyyHBBmZpblgDAzs6wyDQhfxmRm1ldlGhBmZtZXDggzM8tyQJiZWZYDwszMshwQZmaW5YAwM7MsB4SZmWU5IMzMLKvLgJA0StJqSWslbZT0jVR+rqTHJa2X9GtJ4zuoP0/SFknbJC0qdQfMzKx/dGcP4igwNyLOBWYD8yRdCNwILIqI9wB3AX/dvqKkSuCHwJXALOBaSbNK1HYzM+tHXQZEFBxMkyPSEMA7gYdT+QrgI5nqc4BtEbEjIpqA24Br+tzqLviBQWZmfdetcxCSKiU9DTQAKyJiFbABuDot8jHgrEzVM4FdRdO7U1luG9dJqpNU19jY2M3mm5lZf+lWQERES0TMBqYBcyS9G/gk8DlJa4BxQFOmau67fHSwjcURURsRtTU1Nd1q/HDwwt7D/P7X7mNbw4HBboqZDTM9uoopIvYCK4F5EbE5Iq6IiAuAW4HtmSq7OXHPYhpQ37umDk/3rn+R15tauHX1rq4XNjMroe5cxVQj6dQ0Phq4DNgsaXIqqwC+CtyQqf4kcLakGZJGAguAJSVqu5mZ9aPu7EFMBR6StI7CB/6KiFhK4YqkZ4HNFPYKbgKQdIakZQAR0Qx8HlgObALuiIiNpe+GmZmVWlVXC0TEOuC8TPn3ge9nyuuB+UXTy4BlfWummZkNtLL8JbWvcjUz67uyDAgzM+s7B4SZmWU5IMzMLKssA8K32jAz67uyDAgzM+s7B4SZmWWVZUAcamoZ7CaYmQ15ZRkQj2x9ebCbYGY25JVlQJiZWd85IMzMLMsBYWZmWQ4IMzPLckAMEZF9Dp+ZWf9xQJiZWZYDwszMshwQZmaW5YAwM7MsB4SZmWU5IMzMLMsBYWZmWQ4IMzPLKtuAmL7onsFugpnZkFa2AWFmZn3jgDAzsywHhJmZZVV1tYCkUcDDQHVa/s6I+Lqk2cANwCigGfhsRKzO1N8JHABagOaIqC1Z683MrN90GRDAUWBuRByUNAJ4VNK9wDeBb0TEvZLmA98BLulgHR+ICD8H1MxsCOkyICIigINpckQaIg3jU/kEoL4/GmhmZoOjO3sQSKoE1gBvB34YEaskfRFYLum7FM5lvL+D6gHcLymAH0fE4r4328zM+lu3TlJHREtEzAamAXMkvRv4DPCliDgL+BLwzx1UvygizgeuBD4n6eLcQpKuk1Qnqa6xsbGn/TAzsxLr0VVMEbEXWAnMAxYCv0yzfgHM6aBOfXptAO7qZLnFEVEbEbU1NTU9adawEPiRcmY2sLoMCEk1kk5N46OBy4DNFM45/HFabC6wNVN3jKRxbePAFcCGkrR8mJA02E0ws2GqO+cgpgI3p/MQFcAdEbFU0l7g+5KqgCPAdQCSzgBujIj5wBTgrvQhVwX8PCLuK303zMys1LpzFdM64LxM+aPABZnyemB+Gt8BnNv3ZpqZ2UAr619SP7BpT79v48ixFvYeaur37ZiZDbSyDohP3VzX79tYsPgJZn9zRb9vx8xsoJV1QAyEp3ftHewmmJn1i7IPiGMtrfzmmT1s3XNgsJtiZjakdOuX1EPZd5dv4ccP7wBg57c+NMitMTMbOsp+D6ItHGx4m/3N+/nbX/knOGY9UfYBUexXT71A4d6DNtzsPXSMf3ni+cFuhtmQMqwC4ou3P83j218Z7GaYmQ0JwyogAPYfaR7sJlgJrNrxCn9161M0Hjg62E0xK1vDLiA+fcsa/uHeTbyw9zD1ew+XbL3NLa0lW5d17c9uXMWv19bz7/7+Nz5saNZPhl1AAPz4tzu46FsP8v5vPciif11HRPBfb32K6Yvu4VBT53sYDfuP8P5/eIDnXn79hPIndrzan03ulc/csoZrfvhvHc5/pn4/R5tbBrBFpVNRdBPDQ00D04e6na+y+7VDnS5z82M7S/rFw2wwDcuAKHbbk7uYcf0ylqwtPBBv1teWM33RPUxfdA8bXtjHU797DYDHtr/MgsWP87d3b6B+3xE+8N2VtLa+8c21ouimq62twZFjg/vB++rrTdy74SXWdvBDvlcOHmX+Dx7hb+5cN7ANK5Gmoj22j/zoMR7a0sBrrzfRcOAIc7+7kl2vHjr+Nyjew2hpDZqae7e399EbHucPv/1Qh/MbDhzh60s28hc3venR7IPijrpdLFj8+GA3w4awsv8dRF9c9X8e7XT+zP+x7Pj4f7pxFQCf/uO3ccNvtx8vf++0Cazbve/49KIrz6FCMGfG6UwZX82jW19m/5Fm/m7pMyes+w9mnMaq515lbHXhT7Sxfj97DzXxxI5XqK6qJAgmjxvFu8+cQGtr0BJBVYVoaQ3qnn+NBYufOL6uVw4e5flXD1EhUSnxnmkTeGRr4RHh/7b9FQ4cOcahphbGjxrBi/sO8/mfP8U//um5nPOW8UQER5tbGVlZQQA/fWwnUyeM4rJ3TWFkVQURweM7XuEdU8YxaWz18W0+9/LrNDW3cuRYC+85cwIVKUH3HTpG9YgK1jz/GmOqq5gyvprJ40ZRWdG925ofPNpMVbtlN790gE/c9CRvGT+Kl/YfAeCPvlP4IP+jsycd7yvAO756Ly2twf1fupjqqgr+57JNfOCdk/n7ZZs4Y8Jo3j55LPesf5Fvf+Q9/Mfaszja3Ep1VcUJt11vam5lRKU41hKMrKpg3+FjjB5RydFjheB5ds9Bih1uaqG6quL4e1AsImgN2PnK69z9dD2fveRtRMDa3Xu5cObpHb4PEfGmW8G3BeHa3fv4cNGe4+aX9nPOW8az79Axxo2qYu/hwuuIyt59PzxyrIXm1jj+v9m+TRFBw4Gj1Iytzva5My8fPMqIygrGjKykqpfts9LRyXj8tra2Nurqen4fpemL7umH1lhPVVWI5tbe/V/NmDTmTYfvTgYza8awo7E07Zp4ygheO3SMsdVVHDza9UUTZ08ee3x8a8OJ4TNj0hgkaDxwlAM9vADj7ZPH0vbx/eK+I8fbMnPSmA4Du/3229qXKweYNLaa8aMLQdL2/r29qD8Hjhxjz/6jjKgUo0dUnnARyYTRI9h3+BijRlQwbeIpHfZjW9p2cX+GqomnjOSOT7+vV3UlrYmI2lK2x3sQQ1h1VQVHe3m4pL/MrBnDOyaP476NL/Wo3qSxI3n5YBPvmjqOpuZWXmh3HP/3zxjPxvr9pWxqj5zzlnElC4iZNWNZ/8I+xlRXdhoQZ0wYRf2+I5w95Y0P1Odefp2KCh0/THbOW8ZRWSGOTGrhN5saAJgyvpo9+0+8umvOjNNY/dyJ58neUbTet54+ht+kux+/Y8o4Kjr48t7SGuwoCvD3TpvAtImj2Xf4GA2ZK8reNXUc40ePQMCRphbq9x3hnVPGHZ9/rKWV+5/Zw7nTTuXUU0YebwMU9qLvf2YP0yaeckKd9l547TCHj7Wc0J+havyoEYPdhBOUVUD4VhpmZqXjg3xmZpblgDAzsywHhJmZZTkgzMwsywFhZmZZDggzM8tyQJiZWZYDwszMsk7KW21IagR6+/ivScDLXS5Vntz34We49hvc9/Z9f2tE1JRyIydlQPSFpLpS349kqHDfh1/fh2u/wX0fiL77EJOZmWU5IMzMLKscA2LxYDdgELnvw89w7Te47/2u7M5BmJlZaZTjHoSZmZWAA8LMzLLKJiAkzZO0RdI2SYsGuz29IeksSQ9J2iRpo6QvpPLTJK2QtDW9Tiyqc33q8xZJHywqv0DS+jTvB0oPMJZULen2VL5K0vQB72gnJFVKekrS0jQ9LPou6VRJd0ranP7+7xtGff9S+n/fIOlWSaPKte+SfiKpQdKGorIB6aukhWkbWyUt7FaDI2LID0AlsB2YCYwE1gKzBrtdvejHVOD8ND4OeBaYBXwHWJTKFwHfTuOzUl+rgRnpPahM81YD7wME3Atcmco/C9yQxhcAtw92v9u9B/8N+DmwNE0Pi74DNwN/mcZHAqcOh74DZwLPAaPT9B3AX5Rr34GLgfOBDUVl/d5X4DRgR3qdmMYndtnewf4HKdGb/j5gedH09cD1g92uEvTrbuByYAswNZVNBbbk+gksT+/FVGBzUfm1wI+Ll0njVRR+janB7mtqzzTgAWAubwRE2fcdGE/hQ1LtyodD388EdqUPripgKXBFOfcdmM6JAdHvfS1eJs37MXBtV20tl0NMbf9kbXansiEr7RqeB6wCpkTEiwDpdXJarKN+n5nG25efUCcimoF9wOn90ome+x7wZaC1qGw49H0m0AjclA6v3ShpDMOg7xHxAvBd4HfAi8C+iLifYdD3IgPR1159RpZLQChTNmSv35U0FvhX4IsRsb+zRTNl0Ul5Z3UGlaSrgIaIWNPdKpmyIdl3Ct/0zgd+FBHnAa9TONTQkbLpezrefg2FQyhnAGMkfbyzKpmyIdn3bihlX3v1HpRLQOwGziqangbUD1Jb+kTSCArh8LOI+GUq3iNpapo/FWhI5R31e3cab19+Qh1JVcAE4NXS96THLgKulrQTuA2YK+kWhkffdwO7I2JVmr6TQmAMh75fBjwXEY0RcQz4JfB+hkff2wxEX3v1GVkuAfEkcLakGZJGUjg5s2SQ29Rj6UqEfwY2RcQ/Fs1aArRddbCQwrmJtvIF6cqFGcDZwOq0m3pA0oVpnX/erk7buj4KPBjpoORgiojrI2JaREyn8Pd7MCI+zvDo+0vALknvTEWXAs8wDPpO4dDShZJOSW2+FNjE8Oh7m4Ho63LgCkkT017bFamsc4N1oqYfTvzMp3DVz3bgK4Pdnl724Q8p7PatA55Ow3wKxxAfALam19OK6nwl9XkL6UqGVF4LbEjz/i9v/Gp+FPALYBuFKyFmDna/M+/DJbxxknpY9B2YDdSlv/2vKFxpMlz6/g1gc2r3v1C4aqcs+w7cSuFcyzEK3+o/NVB9BT6ZyrcBn+hOe32rDTMzyyqXQ0xmZlZiDggzM8tyQJiZWZYDwszMshwQZmaW5YAwM7MsB4SZmWX9fwcpowJXQtyCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "next_wp = [(x,y) for x,y in list(unigrams_counts.items())]\n",
    "next_p = [float(y)/100 for x,y in next_wp]\n",
    "next_p = next_p/np.sum(next_p)\n",
    "next_p =softmax(next_p*0.00001)\n",
    "plt.plot(list(range(len(next_p))),next_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5d444e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نیازم‌ این‌است کمینگاه ندانم‌کجاکنم می‌رو مریخش ;عالم پیامش جهات میانه‌ای\n"
     ]
    }
   ],
   "source": [
    "do_repeat = True\n",
    "\n",
    "generated = []\n",
    "\n",
    "while(len(generated)<10):\n",
    "    token = next_wp[np.random.choice(len(next_wp), 1, replace=False, p=next_p)[0]][0]\n",
    "    if (token not in generated or do_not_repeat):\n",
    "        generated.append(token)\n",
    "\n",
    "print(' '.join(generated))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f14c4e",
   "metadata": {},
   "source": [
    "# Bigram language model of Hafez/Saadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3890210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = create_language_model(unigrams, bigrams, unigrams_counts, bigrams_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c026bec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('حیوانی', 0.011396011396011397)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'چشمه'\n",
    "nextw_p = list(language_model[word].items())\n",
    "nextw_p[np.random.choice(len(nextw_p), 1, replace=False, p=[y for x,y in nextw_p])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "598e8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(language_model, start, length=10):\n",
    "\n",
    "    generated = [start]\n",
    "    pair_w_p = list(language_model[start].items())\n",
    "    \n",
    "    for i in range(length):\n",
    "        idx = np.random.choice(len(pair_w_p), 1, replace=False, p=[y for x,y in pair_w_p])[0]\n",
    "        next_w = pair_w_p[idx][0]\n",
    "        generated.append(next_w)\n",
    "        pair_w_p = list(language_model[next_w].items())\n",
    "    return print(' '.join(generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a9e63104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دوش پرسیدم از وسواس هوای خوشی بما نمیکنی فیض ذوق دریا\n"
     ]
    }
   ],
   "source": [
    " generate(language_model, 'دوش', length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dbb2c3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<h2 style='direction:rtl;'> § استفاده از POS-tags  </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0721ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = POSTagger(model='resources/postagger.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "81f63b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sent(language_model, start):\n",
    "\n",
    "    generated = [start]\n",
    "    pair_w_p = list(language_model[start].items())\n",
    "    tag = tagger.tag([start])[0][1]\n",
    "    while(tag[0]!='V'):\n",
    "        idx = np.random.choice(len(pair_w_p), 1, replace=False, p=[y for x,y in pair_w_p])[0]\n",
    "        next_w = pair_w_p[idx][0]\n",
    "        generated.append(next_w)\n",
    "        tag = tagger.tag(generated)[-1][1]\n",
    "        pair_w_p = list(language_model[next_w].items())\n",
    "    return print(' '.join(generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c25f74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دوش دولت بر سر ندارد\n"
     ]
    }
   ],
   "source": [
    "generate_sent(language_model, 'دوش')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d56f7",
   "metadata": {},
   "source": [
    "<h2 style='direction:rtl;'> § N-gram Language Model </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ae58e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified version of \n",
    "# https://github.com/joshualoehr/ngram-language-model/blob/master/language_model.py\n",
    "from itertools import product\n",
    "import math\n",
    "import nltk\n",
    "\n",
    "\n",
    "class LanguageModel(object):\n",
    "    \"\"\"An n-gram language model trained on a given corpus.\n",
    "    \n",
    "    For a given n and given training corpus, constructs an n-gram language\n",
    "    model for the corpus by:\n",
    "    1. preprocessing the corpus (adding SOS/EOS/UNK tokens)\n",
    "    2. calculating (smoothed) probabilities for each n-gram\n",
    "    Also contains methods for calculating the perplexity of the model\n",
    "    against another corpus, and for generating sentences.\n",
    "    Args:\n",
    "        train_data (list of str): list of sentences comprising the training corpus.\n",
    "        n (int): the order of language model to build (i.e. 1 for unigram, 2 for bigram, etc.).\n",
    "        laplace (int): lambda multiplier to use for laplace smoothing (default 1 for add-1 smoothing).\n",
    "    \"\"\"\n",
    "\n",
    "    SOS = \"<s>\"\n",
    "    EOS = \"</s>\"\n",
    "    UNK = \"<UNK>\"\n",
    "    \n",
    "    def __init__(self, train_data, n, laplace=1):\n",
    "        self.n = n\n",
    "        self.vocab = dict()\n",
    "        self.laplace = laplace\n",
    "        self.tokens = self.preprocess(train_data, n)\n",
    "        self.vocab  = nltk.FreqDist(self.tokens)\n",
    "        self.model  = self._create_model()\n",
    "        self.masks  = list(reversed(list(product((0,1), repeat=n))))\n",
    "\n",
    "    def _smooth(self):\n",
    "        \"\"\"Apply Laplace smoothing to n-gram frequency distribution.\n",
    "        \n",
    "        Here, n_grams refers to the n-grams of the tokens in the training corpus,\n",
    "        while m_grams refers to the first (n-1) tokens of each n-gram.\n",
    "        Returns:\n",
    "            dict: Mapping of each n-gram (tuple of str) to its Laplace-smoothed \n",
    "            probability (float).\n",
    "        \"\"\"\n",
    "        vocab_size = len(self.vocab)\n",
    "\n",
    "        n_grams = nltk.ngrams(self.tokens, self.n)\n",
    "        n_vocab = nltk.FreqDist(n_grams)\n",
    "\n",
    "        m_grams = nltk.ngrams(self.tokens, self.n-1)\n",
    "        m_vocab = nltk.FreqDist(m_grams)\n",
    "\n",
    "        def smoothed_count(n_gram, n_count):\n",
    "            m_gram = n_gram[:-1]\n",
    "            m_count = m_vocab[m_gram]\n",
    "            return (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n",
    "\n",
    "        return { n_gram: smoothed_count(n_gram, count) for n_gram, count in n_vocab.items() }\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Create a probability distribution for the vocabulary of the training corpus.\n",
    "        \n",
    "        If building a unigram model, the probabilities are simple relative frequencies\n",
    "        of each token with the entire corpus.\n",
    "        Otherwise, the probabilities are Laplace-smoothed relative frequencies.\n",
    "        Returns:\n",
    "            A dict mapping each n-gram (tuple of str) to its probability (float).\n",
    "        \"\"\"\n",
    "        if self.n == 1:\n",
    "            num_tokens = len(self.tokens)\n",
    "            return { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
    "        else:\n",
    "            return self._smooth()\n",
    "\n",
    "    def _convert_oov(self, ngram):\n",
    "        \"\"\"Convert, if necessary, a given n-gram to one which is known by the model.\n",
    "        Starting with the unmodified ngram, check each possible permutation of the n-gram\n",
    "        with each index of the n-gram containing either the original token or <UNK>. Stop\n",
    "        when the model contains an entry for that permutation.\n",
    "        This is achieved by creating a 'bitmask' for the n-gram tuple, and swapping out\n",
    "        each flagged token for <UNK>. Thus, in the worst case, this function checks 2^n\n",
    "        possible n-grams before returning.\n",
    "        Returns:\n",
    "            The n-gram with <UNK> tokens in certain positions such that the model\n",
    "            contains an entry for it.\n",
    "        \"\"\"\n",
    "        mask = lambda ngram, bitmask: tuple((token if flag == 1 else \"<UNK>\" for token,flag in zip(ngram, bitmask)))\n",
    "\n",
    "        ngram = (ngram,) if type(ngram) is str else ngram\n",
    "        for possible_known in [mask(ngram, bitmask) for bitmask in self.masks]:\n",
    "            if possible_known in self.model:\n",
    "                return possible_known\n",
    "\n",
    "    def perplexity(self, test_data):\n",
    "        \"\"\"Calculate the perplexity of the model against a given test corpus.\n",
    "        \n",
    "        Args:\n",
    "            test_data (list of str): sentences comprising the training corpus.\n",
    "        Returns:\n",
    "            The perplexity of the model as a float.\n",
    "        \n",
    "        \"\"\"\n",
    "        test_tokens = self.preprocess(test_data, self.n)\n",
    "        test_ngrams = nltk.ngrams(test_tokens, self.n)\n",
    "        N = len(test_tokens)\n",
    "\n",
    "        known_ngrams  = [self._convert_oov(ngram) for ngram in test_ngrams]\n",
    "        probabilities = [self.model[ngram] for ngram in known_ngrams]\n",
    "        \n",
    "        for x,y in zip(known_ngrams, probabilities):\n",
    "            print(x,y)\n",
    "        \n",
    "        return math.exp((-1/N) * sum(map(math.log, probabilities)))\n",
    "\n",
    "    def _best_candidate(self, prev, without=[]):\n",
    "        \n",
    "        blacklist  = [LanguageModel.UNK] + without\n",
    "\n",
    "        if len(prev) < self.n:\n",
    "            prev = [LanguageModel.SOS]*(self.n-1)\n",
    "\n",
    "        candidates = list(((ngram[-1],prob) for ngram,prob in self.model.items() if ngram[:-1]==tuple(prev)))\n",
    "\n",
    "        probs = [y for x,y in candidates]\n",
    "        probs = probs/np.sum(probs)\n",
    "        words = [x for x,y in candidates]\n",
    "\n",
    "        idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
    "        \n",
    "        while words[idx] in blacklist:\n",
    "            idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
    "        \n",
    "        return (words[idx], probs[idx])\n",
    "         \n",
    "    def generate_sentence(self, min_len=12, max_len=24):\n",
    "        sent, prob = ([LanguageModel.SOS] * (max(1, self.n-1)), 1)\n",
    "        while sent[-1] != LanguageModel.EOS:\n",
    "            prev = () if self.n == 1 else tuple(sent[-(self.n-1):])\n",
    "            blacklist = sent + ([LanguageModel.EOS,LanguageModel.SOS] if len(sent) < min_len else [])\n",
    "            next_token, next_prob = self._best_candidate(prev, without=blacklist)\n",
    "            sent.append(next_token)\n",
    "            prob *= next_prob\n",
    "\n",
    "            if len(sent) >= max_len:\n",
    "                sent.append(LanguageModel.EOS)\n",
    "\n",
    "        return (' '.join(sent[(self.n-1):-1]), -1/math.log(prob))\n",
    "    \n",
    "    \n",
    "\n",
    "    def add_sentence_tokens(self, sentences, n):\n",
    "        \"\"\"Wrap each sentence in SOS and EOS tokens.\n",
    "        For n >= 2, n-1 SOS tokens are added, otherwise only one is added.\n",
    "        Args:\n",
    "            sentences (list of str): the sentences to wrap.\n",
    "            n (int): order of the n-gram model which will use these sentences.\n",
    "        Returns:\n",
    "            List of sentences with SOS and EOS tokens wrapped around them.\n",
    "        \"\"\"\n",
    "        sos = ' '.join([LanguageModel.SOS] * (n-1)) if n > 1 else LanguageModel.SOS\n",
    "        return ['{} {} {}'.format(sos, s, LanguageModel.EOS) for s in sentences]\n",
    "\n",
    "    def replace_singletons(self, tokens):\n",
    "        \"\"\"Replace tokens which appear only once in the corpus with <UNK>.\n",
    "\n",
    "        Args:\n",
    "            tokens (list of str): the tokens comprising the corpus.\n",
    "        Returns:\n",
    "            The same list of tokens with each singleton replaced by <UNK>.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(self.vocab) == 0:\n",
    "            self.vocab = nltk.FreqDist(tokens)\n",
    "        return [token if self.vocab[token] > 1 else LanguageModel.UNK for token in tokens]\n",
    "\n",
    "    def preprocess(self, sentences, n):\n",
    "        \"\"\"Add SOS/EOS/UNK tokens to given sentences and tokenize.\n",
    "        Args:\n",
    "            sentences (list of str): the sentences to preprocess.\n",
    "            n (int): order of the n-gram model which will use these sentences.\n",
    "        Returns:\n",
    "            The preprocessed sentences, tokenized by words.\n",
    "        \"\"\"\n",
    "        sentences = self.add_sentence_tokens(sentences, n)\n",
    "        tokens = ' '.join(sentences).split()\n",
    "        tokens = self.replace_singletons(tokens)\n",
    "        return tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9815eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesra_tokens = [' '.join(x) for x in mesra_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1da0c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = LanguageModel(mesra_tokens, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "44ece673",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = list(((ngram[-1],prob) for ngram,prob in self.model.items() if ngram[:-1]==tuple(prev)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d29ee0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نبرد بی دولت تا آمد جمعی زهی لبت آنکه بوئی شیشه در اگر گوئی کاش گل‌های من مه که داد ماه مسیح آن خضر از چارهٔ صد بی‌او\n",
      "0.004860917286486039\n"
     ]
    }
   ],
   "source": [
    "sent, prob= language_model.generate_sentence(min_len=12, max_len=30)\n",
    "\n",
    "print(sent)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "7b22a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', '<s>', 'الا') 0.0005220442607422716\n",
      "('<s>', 'الا', 'یا') 0.0006175478599591468\n",
      "('الا', 'یا', 'ایها') 0.00019074868860276584\n",
      "('یا', 'ایها', 'الساقی') 0.00016698473282442748\n",
      "('ایها', 'الساقی', 'ادر') 0.00014313318542904174\n",
      "('الساقی', 'ادر', 'کاسا') 7.157513002815288e-05\n",
      "('ادر', 'کاسا', 'و') 7.158025339409702e-05\n",
      "('کاسا', 'و', 'ناولها') 7.158025339409702e-05\n",
      "('و', 'ناولها', '</s>') 4.77190303493033e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1394.8209766742411"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model.perplexity([normalizer.normalize('الا یا ایها الساقی ادر کاسا و ناولها')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "66a74e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', '<s>', 'من') 0.00893126237836907\n",
      "('<s>', 'من', 'این') 0.0011055343047294758\n",
      "('من', 'این', '<UNK>') 0.00011866337573571293\n",
      "('این', '<UNK>', '<UNK>') 0.0004963600264725347\n",
      "('<UNK>', '<UNK>', '<UNK>') 0.007975336773674686\n",
      "('<UNK>', '<UNK>', '<UNK>') 0.007975336773674686\n",
      "('<UNK>', '<UNK>', '<UNK>') 0.007975336773674686\n",
      "('<UNK>', '<UNK>', '<UNK>') 0.007975336773674686\n",
      "('<UNK>', '<UNK>', '<UNK>') 0.007975336773674686\n",
      "('خوب', '<UNK>', '</s>') 9.54380606986066e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "169.39914830074972"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model.perplexity(['من این توپ رو نداشتم مشقام رو خوب نوشتم'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f5d6d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', '<s>', 'در') 0.028106970636355807\n",
      "('<s>', 'در', 'آرزوی') 0.0008213473917445036\n",
      "('در', 'آرزوی', 'تو') 0.00014286734766769056\n",
      "('آرزوی', 'تو', '<UNK>') 4.7684898192742357e-05\n",
      "('تو', '<UNK>', '<UNK>') 0.00023485755889053288\n",
      "('<UNK>', '<UNK>', '<UNK>') 0.007975336773674686\n",
      "('سپید', 'گشت', 'و') 4.772130756382725e-05\n",
      "('گشت', 'و', '<UNK>') 4.7545465351242125e-05\n",
      "('و', '<UNK>', 'نیست') 0.000386988094425095\n",
      "('<UNK>', 'نیست', '<UNK>') 0.0002127609276376445\n",
      "('نیست', 'اگر', '<UNK>') 7.155635062611807e-05\n",
      "('اگر', '<UNK>', 'تو') 4.7514967214672624e-05\n",
      "('<UNK>', 'تو', '<UNK>') 0.0002601333774771792\n",
      "('تو', '<UNK>', '<UNK>') 0.00023485755889053288\n",
      "('<UNK>', '<UNK>', 'چشم') 4.467975783571253e-05\n",
      "('<UNK>', 'چشم', '<UNK>') 9.530617107457708e-05\n",
      "('چشم', 'سیاهت', '</s>') 4.77190303493033e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1979.3616938933349"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model.perplexity([normalizer.normalize('در آرزوی تو چشمم سپید گشت و غمی نیست اگر قبول تو افتد فدای چشم سیاهت')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "be613a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', '<s>', '<UNK>') 0.019232218203737193\n",
      "('<s>', '<UNK>', '<UNK>') 0.013821221078381409\n",
      "('<UNK>', '<UNK>', '<UNK>') 0.007975336773674686\n",
      "('<UNK>', 'جام', '<UNK>') 9.541757114572648e-05\n",
      "('<UNK>', '<UNK>', '<UNK>') 0.007975336773674686\n",
      "('جهانی', '<UNK>', 'در') 4.7714476572192006e-05\n",
      "('<UNK>', 'در', '<UNK>') 0.0007979722117912129\n",
      "('در', '<UNK>', '<UNK>') 0.0007965140795577004\n",
      "('<UNK>', '<UNK>', 'و') 0.0026361057123070394\n",
      "('<UNK>', 'و', '<UNK>') 0.006368263678071718\n",
      "('و', '<UNK>', 'در') 0.00043251610553392977\n",
      "('<UNK>', 'در', '<UNK>') 0.0007979722117912129\n",
      "('در', '<UNK>', '<UNK>') 0.0007965140795577004\n",
      "('<UNK>', '<UNK>', '</s>') 0.02182606170274557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "247.86073221856296"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_model.perplexity([normalizer.normalize('قرعه‌کشی پلی‌آف جام جهانی 2022 در اروپا؛ ایتالیا و پرتغال در مسیر مشترک')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e0c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
